<!DOCTYPE html>
<html lang="">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="数据挖掘系列之回归问题"/>




  <meta name="keywords" content="线性回归 逻辑回归 单变量回归 多变量回归 下降方法," />





  <link rel="alternate" href="/atom.xml" title="Ashan Blog">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="http://ashan2012.github.info/2016/01/03//blog/2016/01/03/回归问题.html/"/>


<meta name="description" content="逻辑回归主要用于分类模型以及ctr预测模型。 逻辑回归首先从逻辑函数讲起。 逻辑函数的定义如下：$$F(wx)=\frac{1}{1+{e^{-wx}}}$$ 在逻辑回归问题里用逻辑函数表示样本被判定为正样本的概率，即P(y=+1|x)=F(wx)，则相应的判断负样本的概率为1-P(y=+1|x)。由此可知对新样本分类的问题归结为比较上述两个概率的大小。对于概率函数进行极大似然估计。依据引入的逻辑">
<meta name="keywords" content="线性回归 逻辑回归 单变量回归 多变量回归 下降方法">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘系列之回归问题">
<meta property="og:url" content="http://ashan2012.github.info/2016/01/03//blog/2016/01/03/回归问题.html/index.html">
<meta property="og:site_name" content="Ashan Blog">
<meta property="og:description" content="逻辑回归主要用于分类模型以及ctr预测模型。 逻辑回归首先从逻辑函数讲起。 逻辑函数的定义如下：$$F(wx)=\frac{1}{1+{e^{-wx}}}$$ 在逻辑回归问题里用逻辑函数表示样本被判定为正样本的概率，即P(y=+1|x)=F(wx)，则相应的判断负样本的概率为1-P(y=+1|x)。由此可知对新样本分类的问题归结为比较上述两个概率的大小。对于概率函数进行极大似然估计。依据引入的逻辑">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/lr_maxentroy.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/maxentroy2.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/lr-1.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/lr-2.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/sherman_morrision_1.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/sherman_morrision_2.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/LBFGS_1.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/LBFGS_2.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/LBFGS_3.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/LBFGS_4.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/LBFGS_5.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/own-qn-1.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/own-qn-2.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/own-qn-3.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/ftrl_1.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/ftrl_2.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/ftrl_3.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/ftrl_4.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/ftrl_5.png">
<meta property="og:image" content="http://ashan2012.github.io/images/lr/ftrl_6.png">
<meta property="og:updated_time" content="2017-12-10T14:14:52.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据挖掘系列之回归问题">
<meta name="twitter:description" content="逻辑回归主要用于分类模型以及ctr预测模型。 逻辑回归首先从逻辑函数讲起。 逻辑函数的定义如下：$$F(wx)=\frac{1}{1+{e^{-wx}}}$$ 在逻辑回归问题里用逻辑函数表示样本被判定为正样本的概率，即P(y=+1|x)=F(wx)，则相应的判断负样本的概率为1-P(y=+1|x)。由此可知对新样本分类的问题归结为比较上述两个概率的大小。对于概率函数进行极大似然估计。依据引入的逻辑">
<meta name="twitter:image" content="http://ashan2012.github.io/images/lr/lr_maxentroy.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> 数据挖掘系列之回归问题 - Ashan Blog </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Ashan Blog</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          数据挖掘系列之回归问题
        
      </h1>

      <time class="post-time">
          Jan 3 2016
      </time>
    </header>



    
            <div class="post-content">
            <p><em>逻辑回归主要用于分类模型以及ctr预测模型。</em></p>
<p>逻辑回归首先从逻辑函数讲起。</p>
<p>逻辑函数的定义如下：$$F(wx)=\frac{1}{1+{e^{-wx}}}$$</p>
<p>在逻辑回归问题里用逻辑函数表示样本被判定为正样本的概率，即P(y=+1|x)=F(wx)，则相应的判断负样本的概率为1-P(y=+1|x)。由此可知对新样本分类的问题归结为比较上述两个概率的大小。对于概率函数进行极大似然估计。依据引入的逻辑函数进行极大似然估计的步骤详见图片推导过程。 </p>
<p>逻辑分布理解为限制条件下的最大熵模型：<br>具体推导课件<a href="http://blog.csdn.net/dp_bupt/article/details/50568392" target="_blank" rel="noopener">csdn博客</a><br><a href="http://www.win-vector.com/dfi/LogisticRegressionMaxEnt.pdf" target="_blank" rel="noopener">推导pdf</a></p>
<p>逻辑回归要达到的目的如下：<br><img src="http://ashan2012.github.io/images/lr/lr_maxentroy.png" alt="逻辑回归的目标"><br>有目标函数推到出的函数分布放好为最大熵分布，也是逻辑回归的模型一般化:</p>
<p><img src="http://ashan2012.github.io/images/lr/maxentroy2.png" alt="逻辑回归模型一般化"></p>
<p>具体介绍如下：</p>
<p><img src="http://ashan2012.github.io/images/lr/lr-1.png" alt="逻辑回归1"></p>
<p><img src="http://ashan2012.github.io/images/lr/lr-2.png" alt="逻辑回归2"></p>
<p>BLFG有海森矩阵转换为海森矩阵的逆过程如下:</p>
<p><img src="http://ashan2012.github.io/images/lr/sherman_morrision_1.png" alt="sherman_morrision_1"></p>
<p><img src="http://ashan2012.github.io/images/lr/sherman_morrision_2.png" alt="sherman_morrision_2"></p>
<p>线下训练的常用的算法BFGS算法如下:</p>
<p><img src="http://ashan2012.github.io/images/lr/LBFGS_1.png" alt="BLFGS1"></p>
<p><img src="http://ashan2012.github.io/images/lr/LBFGS_2.png" alt="BLFGS2"></p>
<p><img src="http://ashan2012.github.io/images/lr/LBFGS_3.png" alt="BLFGS3"></p>
<p><img src="http://ashan2012.github.io/images/lr/LBFGS_4.png" alt="BLFGS4"></p>
<p><img src="http://ashan2012.github.io/images/lr/LBFGS_5.png" alt="BLFGS5"></p>
<p>补充LR1规则下训练算法OWL-QN:</p>
<p><img src="http://ashan2012.github.io/images/lr/own-qn-1.png" alt="own-qn-1"></p>
<p><img src="http://ashan2012.github.io/images/lr/own-qn-2.png" alt="own-qn-2"></p>
<p><img src="http://ashan2012.github.io/images/lr/own-qn-3.png" alt="own-qn-3"></p>
<p>补充trust-region-newton-method(trnm)回归:<a href="http://ashan2012.github.io/pdffile/lr/Trust-Region-Newton-Method-for-Large-Scale-Logistic.pdf" target="_blank" rel="noopener">trust-region-newton-method-for-large-scale-logistic-regression</a></p>
<p>补充在线训练ctr的方法:<br>参考论文:<a href="http://ashan2012.github.io/pdffile/lr/ad-click-prediction.pdf" target="_blank" rel="noopener">Ad Click Prediction-a View from the Trenches_H. Brendan McMahan_2013.pdf</a><br><a href="http://www.datakit.cn/blog/2016/05/11/ftrl.html" target="_blank" rel="noopener">具体细节参考来自datakit</a><br>具体内容如下:</p>
<p><img src="http://ashan2012.github.io/images/lr/ftrl_1.png" alt="ftrl_1"></p>
<p><img src="http://ashan2012.github.io/images/lr/ftrl_2.png" alt="ftrl_2"></p>
<p><img src="http://ashan2012.github.io/images/lr/ftrl_3.png" alt="ftrl_3"></p>
<p><img src="http://ashan2012.github.io/images/lr/ftrl_4.png" alt="ftrl_4"></p>
<p><img src="http://ashan2012.github.io/images/lr/ftrl_5.png" alt="ftrl_5"></p>
<p><img src="http://ashan2012.github.io/images/lr/ftrl_6.png" alt="ftrl_6"></p>
<p>附：各个优化算法参考<a href="http://blog.csdn.net/langb2014/article/details/48915425" target="_blank" rel="noopener">csdn博客</a></p>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/线性回归-逻辑回归-单变量回归-多变量回归-下降方法/">线性回归 逻辑回归 单变量回归 多变量回归 下降方法</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/06/15/blog/2016/06/15/jieba源码阅读.html/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">源码阅读系列之jieba</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2015/12/14/blog/2015/12/14/特征工程.html/">
        <span class="next-text nav-default">数据挖掘系列之特征工程</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2012 -
    
    2017
    <span class="footer-author">SuperAshan.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/henryhuang/hexo-theme-polarbearsimple">Polar Bear Simple</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
