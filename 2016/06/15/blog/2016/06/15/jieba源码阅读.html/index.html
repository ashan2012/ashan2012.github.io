<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="jieba trie 源码 源代码 HMM 维特比 viterbi," />





  <link rel="alternate" href="/atom.xml" title="Ashan Blog" type="application/atom+xml" />






<meta name="description" content="结巴分词用到的的原理：基于Trie树结构实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG)采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法 阅读源码的版本有点老，为0.38 第一点，生成trie树init文件中gen_pddict函数: 123456789101112131415161">
<meta name="keywords" content="jieba trie 源码 源代码 HMM 维特比 viterbi">
<meta property="og:type" content="article">
<meta property="og:title" content="源码阅读系列之jieba">
<meta property="og:url" content="http://ashan2012.github.info/2016/06/15//blog/2016/06/15/jieba源码阅读.html/index.html">
<meta property="og:site_name" content="Ashan Blog">
<meta property="og:description" content="结巴分词用到的的原理：基于Trie树结构实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG)采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法 阅读源码的版本有点老，为0.38 第一点，生成trie树init文件中gen_pddict函数: 123456789101112131415161">
<meta property="og:image" content="http://superashan.github.io/images/jieba/vterbi_01.png">
<meta property="og:updated_time" content="2017-12-10T13:58:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="源码阅读系列之jieba">
<meta name="twitter:description" content="结巴分词用到的的原理：基于Trie树结构实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG)采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法 阅读源码的版本有点老，为0.38 第一点，生成trie树init文件中gen_pddict函数: 123456789101112131415161">
<meta name="twitter:image" content="http://superashan.github.io/images/jieba/vterbi_01.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://ashan2012.github.info/2016/06/15//blog/2016/06/15/jieba源码阅读.html/"/>





  <title>源码阅读系列之jieba | Ashan Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ashan Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            Schedule
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://ashan2012.github.info/2016/06/15/blog/2016/06/15/jieba源码阅读.html/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="super ashan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ashan Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">源码阅读系列之jieba</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-06-15T00:00:00+08:00">
                2016-06-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/源码阅读/" itemprop="url" rel="index">
                    <span itemprop="name">源码阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>结巴分词用到的的原理：<br>基于Trie树结构实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG)<br>采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合<br>对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法</p>
<p>阅读源码的版本有点老，为0.38</p>
<p>第一点，生成trie树<br><strong>init</strong>文件中gen_pddict函数:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def gen_pfdict(self, f): </span><br><span class="line">    lfreq = &#123;&#125;           #f为dict的路径</span><br><span class="line">    ltotal = 0 </span><br><span class="line">    f_name = resolve_filename(f)</span><br><span class="line">    for lineno, line in enumerate(f, 1): </span><br><span class="line">        try:</span><br><span class="line">            line = line.strip().decode(&apos;utf-8&apos;)  #注意编码为utf-8</span><br><span class="line">            word, freq = line.split(&apos; &apos;)[:2]     #按照空格分割，第一列word,第二列频率</span><br><span class="line">            freq = int(freq)</span><br><span class="line">            lfreq[word] = freq                   #lfreq存储每个词对应的频率</span><br><span class="line">            ltotal += freq                       #ltotal对应总词的数目，算词概率</span><br><span class="line">            for ch in xrange(len(word)):</span><br><span class="line">                wfrag = word[:ch + 1]</span><br><span class="line">                if wfrag not in lfreq:</span><br><span class="line">                    lfreq[wfrag] = 0 </span><br><span class="line">        except ValueError:</span><br><span class="line">            raise ValueError(</span><br><span class="line">                &apos;invalid dictionary entry in %s at Line %s: %s&apos; % (f_name, lineno, line))</span><br><span class="line">    f.close()</span><br><span class="line">    return lfreq, ltotal</span><br></pre></td></tr></table></figure>
<p>这里生成的trie树就是一个字典，key为word，value为fre的字典，词语中单个汉字对应的是fre为0<br>DAG是生成一个dict+list的格式，找出所有的词,存储在DAG中，对每个sentence生成一个DAG<br>DAG {0:[1,2,3],1:[3,5],3:[4,5]},表示0-1表示一个词，0-2也是一个词，0-3也是一个词，1-3是一个词，可以看出jieba使用的是正向匹配</p>
<p>不使用HMM的情况下，直接计算DAG的最大概率，以每一个DAG的key找出value中中的最大概率的词语：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def calc(self, sentence, DAG, route):</span><br><span class="line">    N = len(sentence)</span><br><span class="line">    route[N] = (0, 0)</span><br><span class="line">    logtotal = log(self.total)</span><br><span class="line">    for idx in xrange(N - 1, -1, -1):</span><br><span class="line">        route[idx] = max((log(self.FREQ.get(sentence[idx:x + 1]) or 1) -</span><br><span class="line">                          logtotal + route[x + 1][0], x) for x in DAG[idx])</span><br><span class="line">        #相当于计算DAG每个起点到末尾的最大概率分词。rout[idx]函数</span><br></pre></td></tr></table></figure>
<p>route对应list，每一项对应一个DAG项，结果为tuple，tuple第一项概率值，第二项为词语结尾<br>不适用HMM分词的话，直接匹配词语项:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def __cut_DAG_NO_HMM(self, sentence):</span><br><span class="line">    DAG = self.get_DAG(sentence)</span><br><span class="line">    route = &#123;&#125;</span><br><span class="line">    self.calc(sentence, DAG, route)</span><br><span class="line">    x = 0</span><br><span class="line">    N = len(sentence)</span><br><span class="line">    buf = &apos;&apos;</span><br><span class="line">    while x &lt; N:</span><br><span class="line">        y = route[x][1] + 1</span><br><span class="line">        l_word = sentence[x:y]</span><br><span class="line">        if re_eng.match(l_word) and len(l_word) == 1:</span><br><span class="line">            buf += l_word</span><br><span class="line">            x = y    #连续英文算一个词</span><br><span class="line">        else:</span><br><span class="line">            if buf:</span><br><span class="line">                yield buf</span><br><span class="line">                buf = &apos;&apos;</span><br><span class="line">            yield l_word</span><br><span class="line">            x = y</span><br><span class="line">    if buf:</span><br><span class="line">        yield buf</span><br><span class="line">        buf = &apos;&apos;</span><br></pre></td></tr></table></figure>
<p>使用HMM分词的函数为__cut__DAG:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">def __cut_DAG(self, sentence):</span><br><span class="line">    DAG = self.get_DAG(sentence)</span><br><span class="line">    route = &#123;&#125;</span><br><span class="line">    self.calc(sentence, DAG, route)</span><br><span class="line">    x = 0</span><br><span class="line">    buf = &apos;&apos;</span><br><span class="line">    N = len(sentence)</span><br><span class="line">    while x &lt; N:</span><br><span class="line">        y = route[x][1] + 1</span><br><span class="line">        l_word = sentence[x:y]</span><br><span class="line">        if y - x == 1:</span><br><span class="line">            buf += l_word     #单个字连续会连在一起用HMM分词</span><br><span class="line">        else:</span><br><span class="line">            if buf:</span><br><span class="line">                if len(buf) == 1:   #如果下一个是词语，那上一个字就是单个字输出</span><br><span class="line">                    yield buf</span><br><span class="line">                    buf = &apos;&apos;</span><br><span class="line">                else:</span><br><span class="line">                    if not self.FREQ.get(buf):          #连续字在词典中找不到，HMM</span><br><span class="line">                        recognized = finalseg.cut(buf) </span><br><span class="line">                        for t in recognized:</span><br><span class="line">                            yield t</span><br><span class="line">                    else:                            #连续字在词典中找到了，输出</span><br><span class="line">                        for elem in buf:</span><br><span class="line">                            yield elem</span><br><span class="line">                    buf = &apos;&apos;</span><br><span class="line">            yield l_word</span><br><span class="line">        x = y</span><br><span class="line">    if buf:</span><br><span class="line">        if len(buf) == 1:</span><br><span class="line">            yield buf</span><br><span class="line">        elif not self.FREQ.get(buf):</span><br><span class="line">            recognized = finalseg.cut(buf)</span><br><span class="line">            for t in recognized:</span><br><span class="line">                yield t</span><br><span class="line">        else:</span><br><span class="line">            for elem in buf:</span><br><span class="line">                yield elem</span><br></pre></td></tr></table></figure>
<p>其中新词的识别通过HMM实现，对要识别的字符串作为观测序列，状态集合包括(B,M,E,S)，分别对应开始，中间，结束，单字四个状态，在finalseg文件夹有线下算好的HMM模型，prob_start.py对应初始概率，prob_trans.py对应于状态转移矩阵，prob_emit.py对应观测概率。最大概率的状态序列对应为HMM的解码问题，解码使用维特比算法。就是前向算法将加变为max。</p>
<p>HMM函数位于finalseg文件夹下面，在<strong>init</strong>.py，如基于函数为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def __cut(sentence):</span><br><span class="line">    global emit_P</span><br><span class="line">    prob, pos_list = viterbi(sentence, &apos;BMES&apos;, start_P, trans_P, emit_P)</span><br><span class="line">    begin, nexti = 0, 0</span><br><span class="line">    # print pos_list, sentence</span><br><span class="line">    for i, char in enumerate(sentence):</span><br><span class="line">        pos = pos_list[i]</span><br><span class="line">        if pos == &apos;B&apos;:</span><br><span class="line">            begin = i </span><br><span class="line">        elif pos == &apos;E&apos;:</span><br><span class="line">            yield sentence[begin:i + 1]</span><br><span class="line">            nexti = i + 1 </span><br><span class="line">        elif pos == &apos;S&apos;:</span><br><span class="line">            yield char</span><br><span class="line">            nexti = i + 1 </span><br><span class="line">    if nexti &lt; len(sentence):</span><br><span class="line">        yield sentence[nexti:]</span><br></pre></td></tr></table></figure></p>
<p>viterbi输出标注的BMSE状态序列，按照状态序列可知分词结果:<br>维特比算法流程如下:<br><img src="http://superashan.github.io/images/jieba/vterbi_01.png" alt="维特比算法流程图"></p>
<p>具体的代码中如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def viterbi(obs, states, start_p, trans_p, emit_p):</span><br><span class="line">    V = [&#123;&#125;]  # tabular</span><br><span class="line">    path = &#123;&#125;</span><br><span class="line">    for y in states:  # init   #开始的状态</span><br><span class="line">        V[0][y] = start_p[y] + emit_p[y].get(obs[0], MIN_FLOAT)  #V存储每个时间节                    </span><br><span class="line">                                                                #点，每个状态的概率</span><br><span class="line">        path[y] = [y]      #path存储以y状态结束的最大概率状态序列</span><br><span class="line">    for t in xrange(1, len(obs)):</span><br><span class="line">        V.append(&#123;&#125;)</span><br><span class="line">        newpath = &#123;&#125;</span><br><span class="line">        for y in states:</span><br><span class="line">            em_p = emit_p[y].get(obs[t], MIN_FLOAT)</span><br><span class="line">            (prob, state) = max(</span><br><span class="line">                [(V[t - 1][y0] + trans_p[y0].get(y, MIN_FLOAT) + em_p, y0) for y0 in PrevStatus[y]])</span><br><span class="line">            V[t][y] = prob</span><br><span class="line">            newpath[y] = path[state] + [y] </span><br><span class="line">        path = newpath</span><br><span class="line"></span><br><span class="line">    (prob, state) = max((V[len(obs) - 1][y], y) for y in &apos;ES&apos;)</span><br><span class="line"></span><br><span class="line">    return (prob, path[state])</span><br></pre></td></tr></table></figure>
<p>到此为止，结巴分词的原理已经讲完！</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/jieba-trie-源码-源代码-HMM-维特比-viterbi/" rel="tag"># jieba trie 源码 源代码 HMM 维特比 viterbi</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/01/03/blog/2016/01/03/回归问题.html/" rel="next" title="数据挖掘系列之回归问题">
                <i class="fa fa-chevron-left"></i> 数据挖掘系列之回归问题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/11/08/blog/2016/11/08/最小二乘法.html/" rel="prev" title="数据基础系列之一：最小二乘法">
                数据基础系列之一：最小二乘法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">super ashan</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">Kategorien</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">Tags</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">super ashan</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
